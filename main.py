from fastapi import FastAPI, HTTPException, Request
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse
from pydantic import BaseModel
import psycopg2
from psycopg2.extras import RealDictCursor
from psycopg2 import sql
import os
from typing import List, Dict, Any, Optional
from dotenv import load_dotenv
import datetime
import math

load_dotenv()

# è¨­å®š API æ–‡ä»¶æ¨™é¡Œ
app = FastAPI(title="æˆç¸¾è¨ˆç®—èˆ‡ç®¡ç†ç³»çµ±", description="ç”¨æ–¼ç®¡ç†æˆç¸¾è³‡æ–™åº«çš„å¾Œç«¯ API")

# è³‡æ–™åº«é€£ç·š
def get_db_connection():
    try:
        conn = psycopg2.connect(
            host="localhost",
            database="final_project", # è«‹ç¢ºèªè³‡æ–™åº«åç¨±
            user="postgres",
            password=os.getenv("PASSWORD")
        )
        return conn
    except Exception as e:
        print("DB Connection Error:", e)
        return None

# é€šç”¨çš„æ›´æ–°æ¨¡å‹
class UpdatePayload(BaseModel):
    data: Dict[str, Any]      
    conditions: Dict[str, Any] 

# é€šç”¨çš„æ–°å¢æ¨¡å‹
class CreatePayload(BaseModel):
    data: Dict[str, Any]

# 1. å–å¾—æ‰€æœ‰è¡¨æ ¼åç¨± (å«éæ¿¾åŠŸèƒ½)
@app.get("/api/tables")
def get_tables():
    conn = get_db_connection()
    if not conn:
        return []
    
    cur = conn.cursor()
    cur.execute("""
        SELECT table_name 
        FROM information_schema.tables 
        WHERE table_schema = 'public' 
        AND table_type = 'BASE TABLE'
        ORDER BY table_name;
    """)
    all_tables = [row[0] for row in cur.fetchall()]
    
    cur.close()
    conn.close()

    # éæ¿¾æ¸…å–®ï¼šéš±è—ä¸æƒ³é¡¯ç¤ºçš„è¡¨æ ¼
    exclude_list = ['sqlite_sequence'] 
    real_tables = [t for t in all_tables if t not in exclude_list]

    return real_tables

# 2. å–å¾—æŒ‡å®šè¡¨æ ¼çš„æ¬„ä½è³‡è¨Š
@app.get("/api/columns/{table_name}")
def get_columns(table_name: str):
    conn = get_db_connection()
    cur = conn.cursor(cursor_factory=RealDictCursor)
    
    query = sql.SQL("""
        SELECT column_name, data_type 
        FROM information_schema.columns 
        WHERE table_name = %s 
        ORDER BY ordinal_position;
    """)
    cur.execute(query, (table_name,))
    columns = cur.fetchall()
    
    cur.close()
    conn.close()
    return columns

# ==========================================
# 3. å–å¾—è¡¨æ ¼è³‡æ–™ (ğŸš€ æ ¸å¿ƒä¿®æ”¹ï¼šæˆªæ–· 1000 ç­† + åˆ†é )
# ==========================================
@app.get("/api/data/{table_name}")
def get_data(
    table_name: str, 
    sort_by: Optional[str] = None, 
    order: str = "ASC",
    page: int = 1,      
    limit: int = 100    # é è¨­æ¯é  100 ç­†
):
    conn = get_db_connection()
    cur = conn.cursor(cursor_factory=RealDictCursor)
    
    # ğŸ”´ ç¡¬æ€§é™åˆ¶ï¼šæœ€å¤šåªçœ‹å‰ 1000 ç­†
    HARD_LIMIT_RECORDS = 1000
    
    # è¨ˆç®— OFFSET
    offset = (page - 1) * limit

    # å¦‚æœè«‹æ±‚çš„è³‡æ–™èµ·é»å·²ç¶“è¶…é 1000 ç­†ï¼Œç›´æ¥å›å‚³ç©ºå€¼
    if offset >= HARD_LIMIT_RECORDS:
        cur.close()
        conn.close()
        return {
            "data": [],
            "pagination": {
                "current_page": page,
                "per_page": limit,
                "total_count": HARD_LIMIT_RECORDS,
                "total_pages": math.ceil(HARD_LIMIT_RECORDS / limit)
            }
        }

    # å¦‚æœè®€å–çš„ç¯„åœæœƒè¶…é 1000ï¼Œå¼·åˆ¶æŠŠ limit ç¸®å° (ä¾‹å¦‚è®€åˆ°ç¬¬ 950 ç­†æ™‚ï¼Œlimit å‰© 50)
    if offset + limit > HARD_LIMIT_RECORDS:
        limit = HARD_LIMIT_RECORDS - offset

    try:
        # --- æ­¥é©Ÿ 1: ç®—ç¸½ç­†æ•¸ (ä½†åœ¨é€™è£¡æˆ‘å€‘æœ€å¤šåªå›å ± 1000) ---
        count_query = sql.SQL("SELECT COUNT(*) as count FROM {}").format(sql.Identifier(table_name))
        cur.execute(count_query)
        real_count = cur.fetchone()['count']
        
        # é€™è£¡å–æœ€å°å€¼ï¼šå¦‚æœè³‡æ–™åº«åªæœ‰ 50 ç­†ï¼Œå°±é¡¯ç¤º 50ï¼›å¦‚æœæœ‰ 5000 ç­†ï¼Œåªé¡¯ç¤º 1000
        effective_count = min(real_count, HARD_LIMIT_RECORDS)

        # --- æ­¥é©Ÿ 2: æŠ“å–è³‡æ–™ ---
        query_parts = [sql.SQL("SELECT * FROM {}").format(sql.Identifier(table_name))]
        
        if sort_by:
            order_sql = sql.SQL("DESC") if order.upper() == "DESC" else sql.SQL("ASC")
            query_parts.append(sql.SQL("ORDER BY {}").format(sql.Identifier(sort_by)))
            query_parts.append(order_sql)
        
        # ä½¿ç”¨è¨ˆç®—éå¾Œçš„å®‰å…¨ limit
        query_parts.append(sql.SQL("LIMIT {} OFFSET {}").format(sql.Literal(limit), sql.Literal(offset)))
        
        final_query = sql.SQL(" ").join(query_parts)
        
        cur.execute(final_query)
        rows = cur.fetchall()
        
        # æ—¥æœŸè½‰å­—ä¸²
        for row in rows:
            for key, value in row.items():
                if isinstance(value, (datetime.date, datetime.datetime)):
                    row[key] = str(value)
        
        # è¨ˆç®—ç¸½é æ•¸ (åŸºæ–¼æˆªæ–·å¾Œçš„ 1000 ç­†ä¾†ç®—)
        # å¦‚æœ limit æ˜¯ 100ï¼Œeffective_count æ˜¯ 1000ï¼Œé‚£ total_pages å°±æ˜¯ 10
        # åŠ ä¸Š max(1, ...) é¿å…é™¤ä»¥ 0 éŒ¯èª¤
        current_limit = 100 if limit == 0 else limit # é˜²æ­¢ limit è¢«ç¸®æ¸›æˆ 0 å¾Œè¨ˆç®—é æ•¸éŒ¯èª¤ï¼Œé€™è£¡åƒ…ä½œé¡¯ç¤ºç”¨
        total_pages = math.ceil(effective_count / 100) # é€™è£¡ç¨å¾® trickyï¼šç¸½é æ•¸æ‡‰è©²åŸºæ–¼ã€Œå‰ç«¯è¨­å®šçš„æ¯é ç­†æ•¸ã€ä¾†ç®—ï¼Œä½†ç‚ºäº†ç°¡åŒ–ï¼Œæˆ‘å€‘å…ˆç”¨ 100 æˆ–å‰ç«¯å‚³ä¾†çš„åŸå§‹ limit
        
        # æ›´ç²¾æº–çš„ç¸½é æ•¸è¨ˆç®—ï¼šæ‡‰è©²ç”¨ payload è£¡çš„åŸå§‹ limit (ä½†é€™è£¡å·²ç¶“è¢«ä¿®æ”¹äº†)
        # ç°¡å–®åšæ³•ï¼šç›´æ¥å›å‚³è¨ˆç®—çµæœ
        calc_limit = limit if limit > 0 else 100
        total_pages = math.ceil(effective_count / calc_limit)

        # ä¿®æ­£ï¼šå› ç‚ºæˆ‘å€‘å‹•æ…‹èª¿æ•´äº† limit (ä¾‹å¦‚æœ€å¾Œä¸€é  limit è®Šå°)ï¼Œå°è‡´è¨ˆç®—ç¸½é æ•¸å¯èƒ½æ€ªæ€ªçš„
        # æœ€ç©©å¦¥çš„æ–¹å¼æ˜¯ï¼šå‰ç«¯å‚³ä¾†çš„ limit é è¨­æ˜¯ 100ï¼Œæˆ‘å€‘ç”¨ effective_count / 100 ä¾†ç®—
        # ä½†ç‚ºäº†é€šç”¨æ€§ï¼Œæˆ‘å€‘å›å‚³æ™‚çµ±ä¸€ç”¨ effective_count
        
        # é‡æ–°è¨ˆç®—æ¨™æº–ç¸½é æ•¸ (å‡è¨­æ¯é  100)
        standard_limit = 100
        display_total_pages = math.ceil(effective_count / standard_limit)

        return {
            "data": rows,
            "pagination": {
                "current_page": page,
                "per_page": limit,
                "total_count": effective_count,
                "total_pages": display_total_pages 
            }
        }

    except Exception as e:
        print(e)
        return {"data": [], "pagination": {"current_page": 1, "total_count": 0, "total_pages": 0}}
        
    finally:
        cur.close()
        conn.close()

# 4. é€šç”¨æ–°å¢åŠŸèƒ½
@app.post("/api/data/{table_name}")
def create_data(table_name: str, payload: CreatePayload):
    conn = get_db_connection()
    cur = conn.cursor()
    
    data = payload.data
    columns = list(data.keys())
    values = list(data.values())
    
    try:
        query = sql.SQL("INSERT INTO {} ({}) VALUES ({})").format(
            sql.Identifier(table_name),
            sql.SQL(', ').join(map(sql.Identifier, columns)),
            sql.SQL(', ').join(sql.Placeholder() * len(values))
        )
        cur.execute(query, values)
        conn.commit()
    except Exception as e:
        conn.rollback()
        raise HTTPException(status_code=400, detail=str(e))
    finally:
        cur.close()
        conn.close()
    return {"message": "æ–°å¢æˆåŠŸ"}

# 5. é€šç”¨æ›´æ–°åŠŸèƒ½
@app.put("/api/data/{table_name}")
def update_data(table_name: str, payload: UpdatePayload):
    conn = get_db_connection()
    cur = conn.cursor()
    
    new_data = payload.data      
    conditions = payload.conditions 
    
    if not conditions:
        raise HTTPException(status_code=400, detail="ç„¡æ³•æ›´æ–°ï¼šæ‰¾ä¸åˆ°åŸå§‹è³‡æ–™å°æ‡‰æ¢ä»¶")

    try:
        set_clause = sql.SQL(', ').join(
            sql.Composed([sql.Identifier(k), sql.SQL(" = "), sql.Placeholder()])
            for k in new_data.keys()
        )
        
        where_clause = sql.SQL(' AND ').join(
            sql.Composed([sql.Identifier(k), sql.SQL(" = "), sql.Placeholder()])
            for k in conditions.keys()
        )
        
        query = sql.SQL("UPDATE {} SET {} WHERE {}").format(
            sql.Identifier(table_name),
            set_clause,
            where_clause
        )
        
        params = list(new_data.values()) + list(conditions.values())
        
        cur.execute(query, params)
        conn.commit()
        
        if cur.rowcount == 0:
            return {"message": "æ›´æ–°å¤±æ•—ï¼šæ‰¾ä¸åˆ°åŸå§‹è³‡æ–™æˆ–è³‡æ–™æœªè®Šå‹•", "status": "failed"}
            
    except Exception as e:
        conn.rollback()
        raise HTTPException(status_code=400, detail=str(e))
    finally:
        cur.close()
        conn.close()
    return {"message": "æ›´æ–°æˆåŠŸ"}

# 6. é€šç”¨åˆªé™¤åŠŸèƒ½
@app.post("/api/data/{table_name}/delete")
def delete_data(table_name: str, payload: CreatePayload):
    conn = get_db_connection()
    cur = conn.cursor()
    
    conditions = payload.data
    
    try:
        where_clause = sql.SQL(' AND ').join(
            sql.Composed([sql.Identifier(k), sql.SQL(" = "), sql.Placeholder()])
            for k in conditions.keys()
        )
        
        query = sql.SQL("DELETE FROM {} WHERE {}").format(
            sql.Identifier(table_name),
            where_clause
        )
        
        cur.execute(query, list(conditions.values()))
        conn.commit()
    except Exception as e:
        conn.rollback()
        raise HTTPException(status_code=400, detail=str(e))
    finally:
        cur.close()
        conn.close()
    return {"message": "åˆªé™¤æˆåŠŸ"}

app.mount("/static", StaticFiles(directory="static"), name="static")

@app.get("/")
def read_root():
    return FileResponse('static/index.html')